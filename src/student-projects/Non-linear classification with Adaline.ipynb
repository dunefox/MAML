{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaline for non-linear classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to classify a set of data, which is not linearly seperable, using an Adaline. Therefore we introduce an additional dimension to the training data, that is calculated from the given components using a function `phi`.\n",
    "\n",
    "The Adaline in this case uses linear activation and the quadratic loss. `phi` is applied within the Adaline, so that the training data do not have to be prepared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [10, 8]\n",
    "matplotlib.rc(\"savefig\", dpi=200)\n",
    "\n",
    "from IPython.display import display, Javascript\n",
    "\n",
    "disable_js = \"\"\"\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}\n",
    "\"\"\"\n",
    "display(Javascript(disable_js))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# module for file access\n",
    "import os.path\n",
    "\n",
    "# global file name of our data source\n",
    "file_name = 'wine.csv'\n",
    "\n",
    "def fetch_wine_data():\n",
    "    '''\n",
    "    Fetch data from an internet archive and save as file `wine.csv`.\n",
    "    '''\n",
    "\n",
    "    df = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data',\n",
    "                     header=None)\n",
    "    df.to_csv(file_name, header=None, index=False)\n",
    "\n",
    "    return\n",
    "\n",
    "# fetch data from internet source only if the file is not available locally\n",
    "if not os.path.exists(file_name):\n",
    "    fetch_wine_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_name, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_wine_data(df):\n",
    "    ''' \n",
    "    Fetches 2d data points from the wine data from the pandas dataframe `df` and\n",
    "    return (X, Y), where X is a list of 2d points and Y a list of labels.\n",
    "    '''\n",
    "    \n",
    "    X = df.iloc[:, [7,10]].values\n",
    "    Y = df.iloc[:, 0].values \n",
    "    Y = np.where(Y == 1, -1, 1)\n",
    "    \n",
    "    # to make it more realistic, we randomize the data\n",
    "    indices = np.random.permutation(len(X))\n",
    "    # to avoid overflows, we normalize the data\n",
    "    X_rand = [X[i]/np.array([2, 5])-[1.5, 1.5] for i in indices]\n",
    "    Y_rand = [Y[i] for i in indices]\n",
    "    \n",
    "    X_rand = np.array(X_rand)\n",
    "    \n",
    "    # return the randomized lists as numpy arrays\n",
    "    return X_rand, np.array(Y_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_2d(X, Y):\n",
    "    '''\n",
    "    Plot the data X, wine #1 in orange, and others in blue.\n",
    "    '''\n",
    "\n",
    "    # divide data depedning on the label: wine 1 or other\n",
    "    X_set1 = []\n",
    "    X_set2 = []\n",
    "    for x, y in zip(X, Y):\n",
    "        if y == -1:\n",
    "            X_set1.append(x)\n",
    "        else:\n",
    "            X_set2.append(x)\n",
    "   \n",
    "    # convert to numpy array\n",
    "    X_set1 = np.array(X_set1)\n",
    "    X_set2 = np.array(X_set2)\n",
    "\n",
    "    # plot the two lists with different styles\n",
    "    plt.scatter(X_set1[:, 0], X_set1[:, 1],\n",
    "                color='tab:orange', marker='o', label='wine #1')\n",
    "    plt.scatter(X_set2[:, 0], X_set2[:, 1],\n",
    "                color='tab:blue', marker='o', label='other wine')\n",
    "\n",
    "    # decorate plot\n",
    "    plt.xlabel('~flavanoids')\n",
    "    plt.ylabel('~color intensity')\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_all, Y_all = prep_wine_data(df)\n",
    "\n",
    "plot_data_2d(X_all, Y_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the points corresponding to wine 1 are centered around (0,0), we calculate roughly the norm of the data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi(x, y):\n",
    "    return np.sqrt(5*x**2+y**2) # Use 0 for linear classification of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_3d(X, Y):\n",
    "    '''\n",
    "    Plot the data X, wine #1 in orange, and others in blue.\n",
    "    '''\n",
    "\n",
    "    # divide data depedning on the label: wine 1 or other\n",
    "    X_set1 = []\n",
    "    X_set2 = []\n",
    "    for x, y in zip(X, Y):\n",
    "        if y == -1:\n",
    "            X_set1.append(x)\n",
    "        else:\n",
    "            X_set2.append(x)\n",
    "   \n",
    "    # convert to numpy array\n",
    "    X_set1 = np.array(X_set1)\n",
    "    X_set2 = np.array(X_set2)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    # plot the two lists with different styles\n",
    "    ax.scatter(X_set1[:, 0], X_set1[:, 1], phi(X_set1[:,0], X_set1[:,1]),\n",
    "               color='tab:orange', marker='o', label='wine #1')\n",
    "    ax.scatter(X_set2[:, 0], X_set2[:, 1], phi(X_set2[:,0], X_set2[:,1]),\n",
    "               color='tab:blue', marker='o', label='other wine')\n",
    "\n",
    "    # decorate plot\n",
    "    ax.set_xlabel('~flavanoids')\n",
    "    ax.set_ylabel('~color intensity')\n",
    "    ax.set_zlabel(r'$\\varphi$')\n",
    "    ax.legend(loc='upper right')\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_3d(X_all, Y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adaline:\n",
    "\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        initialize class for `num` input signals\n",
    "        '''\n",
    "\n",
    "        # weights of the Adaline, initialized to zero\n",
    "        # note the '1 + ' as the first weight entry is the threshold\n",
    "        self.w_ = np.zeros(4)\n",
    "\n",
    "        return\n",
    "    \n",
    "    def vector_phi(self, X):\n",
    "        newx = [[X[i,0], X[i,1], phi(X[i,0], X[i,1])] for i in range(len(X))]\n",
    "        return np.array(newx)\n",
    "    \n",
    "    def activation_input(self, X):\n",
    "        '''\n",
    "        calculate the activation input of the neuron\n",
    "        '''\n",
    "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
    "\n",
    "    def classify(self, X):\n",
    "        '''\n",
    "        classify the data by sending the activation input through a step function\n",
    "        '''\n",
    "        return np.where(self.activation_input(self.vector_phi(X)) >= 0.0, 1, -1)\n",
    "    \n",
    "    def learn(self, X_train, Y_train, eta=0.01, epochs=1000):\n",
    "        '''\n",
    "        fit training data according to eta and n_iter\n",
    "        and log the errors in errors_\n",
    "        '''\n",
    "\n",
    "        # we initialize two list, each for the misclassifications and the cost function\n",
    "        self.train_errors_ = []\n",
    "        self.train_loss_ = []\n",
    "        \n",
    "        phi_X_train = self.vector_phi(X_train)\n",
    "\n",
    "        # for all the epoch\n",
    "        for _ in range(epochs):\n",
    "            # classify the traning features\n",
    "            Z = self.classify(X_train)\n",
    "            # count the misqualifications for the logging\n",
    "            err = 0\n",
    "            for z, y in zip(Z, Y_train):\n",
    "                err += int(z != y)\n",
    "            # ans save them in the list for later use\n",
    "            self.train_errors_.append(err)\n",
    "            \n",
    "            # compute the activation input of the entire traning features\n",
    "            output = self.activation_input(phi_X_train)\n",
    "            # and then the deviation from the labels\n",
    "            delta = Y_train - output\n",
    "            # the following is an implmentation of the adaline update rule\n",
    "            self.w_[1:] += eta * phi_X_train.T.dot(delta)\n",
    "            self.w_[0] += eta * delta.sum()\n",
    "            # and finally, we record the loss function\n",
    "            loss = (delta ** 2).sum() / 2.0\n",
    "            # and save it for later use\n",
    "            self.train_loss_.append(loss)\n",
    "\n",
    "        return\n",
    "    \n",
    "    def plot_train_loss(self):\n",
    "        '''\n",
    "        plots the loss function value per epoch\n",
    "        '''\n",
    "\n",
    "        # create two lists, one enumerating the epochs, the other the cost values\n",
    "        epochs, num_errs = np.arange(len(self.train_loss_)), np.array(self.train_loss_)\n",
    "\n",
    "        # plot the loss per epoch\n",
    "        fig = plt.figure()\n",
    "        axs = plt.gca()\n",
    "        axs.set_xlabel('epoch')\n",
    "        axs.set_ylabel('cost')\n",
    "        axs.set_title('Loss during training')\n",
    "        plt.plot(epochs, num_errs)\n",
    "\n",
    "        return\n",
    "\n",
    "    def plot_decision_regions(self, X, Y, X_train, Y_train, resolution):\n",
    "\n",
    "        # set up a 2d mesh of data points with resolution `resolution`\n",
    "        x1_min, x1_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "        x2_min, x2_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "\n",
    "        xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                               np.arange(x2_min, x2_max, resolution))\n",
    "\n",
    "        # start new plot\n",
    "        fig = plt.figure()\n",
    "        axs = plt.gca()\n",
    "\n",
    "        # make fictitious feature data out of the above 2d mesh\n",
    "        x_mesh = np.array( [xx1.ravel(), xx2.ravel()] ).T\n",
    "        # let the Adaline classify these features\n",
    "        Z = self.classify(x_mesh)\n",
    "        Z = Z.reshape(xx1.shape)\n",
    "\n",
    "        # plot the mesh as contour plot\n",
    "        axs.contourf(xx1, xx2, Z, alpha=0.4, cmap=matplotlib.colors.ListedColormap(['tab:orange', 'tab:blue']))\n",
    "        axs.set_xlim(xx1.min(), xx1.max())\n",
    "        axs.set_ylim(xx2.min(), xx2.max())\n",
    "        \n",
    "        # sort the input data according to the flower species\n",
    "        X_setosa = []\n",
    "        X_other = []\n",
    "        for x, y in zip(X, Y):\n",
    "            if y == -1:\n",
    "                X_setosa.append(x)\n",
    "            else:\n",
    "                X_other.append(x)\n",
    "\n",
    "        # turn the array into numpy arrays\n",
    "        X_setosa = np.array(X_setosa)\n",
    "        X_other = np.array(X_other)\n",
    "\n",
    "        # and make a scatter plot with different styles for the two different species\n",
    "        axs.scatter(X_setosa[:, 0], X_setosa[:, 1], \n",
    "                    color='tab:orange', marker='.', label='wine 1')\n",
    "        axs.scatter(X_other[:, 0], X_other[:, 1], \n",
    "                    color='tab:blue', marker='.', label='other')\n",
    "        \n",
    "        # sort the training data according to the flower species\n",
    "        X_setosa = []\n",
    "        X_other = []\n",
    "        for x, y in zip(X_train, Y_train):\n",
    "            if y == -1:\n",
    "                X_setosa.append(x)\n",
    "            else:\n",
    "                X_other.append(x)\n",
    "\n",
    "        # turn the array into numpy arrays\n",
    "        X_setosa = np.array(X_setosa)\n",
    "        X_other = np.array(X_other)\n",
    "        \n",
    "        # and make a scatter plot with different styles for the two different species\n",
    "        axs.scatter(X_setosa[:, 0], X_setosa[:, 1], \n",
    "                    color='tab:orange', marker='x', label='wine 1 training')\n",
    "        axs.scatter(X_other[:, 0], X_other[:, 1], \n",
    "                    color='tab:blue', marker='x', label='other wine training')\n",
    "\n",
    "        # add some additional annotations of the plot\n",
    "        axs.set_xlabel('~flavanoids')\n",
    "        axs.set_ylabel('~color intensity')\n",
    "        axs.legend(loc='upper right')\n",
    "        axs.set_title('Adaline')\n",
    "\n",
    "        return\n",
    "\n",
    "    def plot_train_errors(self):\n",
    "        '''\n",
    "        plot the number of misclassifications per epoch\n",
    "        '''\n",
    "\n",
    "        # create two list, one with epoch numbers, and one with the errors per epoch\n",
    "        epochs, num_errs = np.arange(len(self.train_errors_)), np.array(self.train_errors_)\n",
    "\n",
    "        # plot the above data\n",
    "        fig = plt.figure()\n",
    "        axs = plt.gca()\n",
    "        axs.set_xlabel('epoch')\n",
    "        axs.set_ylabel('errors')\n",
    "        axs.set_title('Errors during training')\n",
    "        plt.plot(epochs, num_errs)\n",
    "\n",
    "        return\n",
    "\n",
    "    def efficiency(self, X_test, Y_test): \n",
    "        '''\n",
    "        compute the efficiency = 1 - number of misclassifications / number of data points\n",
    "        '''\n",
    "\n",
    "        err = 0\n",
    "        \n",
    "        # classify the test data\n",
    "        Z = self.classify(X_test)\n",
    "        for z, y in zip(Z, Y_test):\n",
    "            err += int(z != y)\n",
    "\n",
    "        return 1 - float(err) / len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = int(len(X_all)/2)\n",
    "\n",
    "X_train, Y_train = X_all[:train_samples], Y_all[:train_samples]\n",
    "\n",
    "X, Y = X_all[train_samples:], Y_all[train_samples:]\n",
    "\n",
    "ada = Adaline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "ada.learn(X_train, Y_train, eta=0.001, epochs=2000)\n",
    "print(\"Time               = %.03f s\" % float(time.time() - start))\n",
    "\n",
    "eff_train = ada.efficiency(X_train, Y_train)\n",
    "eff_test = ada.efficiency(X, Y)\n",
    "eff_all = ada.efficiency(X_all, Y_all)\n",
    "\n",
    "print('Efficiency (train) =', eff_train)\n",
    "print('Efficiency (test)  =', eff_test)\n",
    "print('Efficiency (all)   =', eff_all)\n",
    "\n",
    "ada.plot_train_loss()\n",
    "ada.plot_train_errors()\n",
    "ada.plot_decision_regions(X, Y, X_train, Y_train, 0.02)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
